{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNsrxANT+XCwJhkQVgqeYT1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xrTITwdd33uG","executionInfo":{"status":"ok","timestamp":1738657804258,"user_tz":-345,"elapsed":29543,"user":{"displayName":"Subhash Dhakal","userId":"00152720141340506237"}},"outputId":"f811edf7-2405-4884-add6-66216a8d463a"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE: 20.250295061325048\n","R²: 0.8827279337661433\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","\n","spark = SparkSession.builder \\\n","    .appName(\"CO2 Emissions Analysis\") \\\n","    .getOrCreate()\n","\n","# Load the dataset\n","data = spark.read.csv(\"/content/CO2 Emissions_Canada.csv\", header=True, inferSchema=True)\n","\n","# Feature Selection\n","from pyspark.ml.feature import VectorAssembler\n","\n","feature_columns = [\"Engine Size(L)\", \"Fuel Consumption City (L/100 km)\",\n","                   \"Fuel Consumption Hwy (L/100 km)\", \"Fuel Consumption Comb (L/100 km)\",\n","                   \"Cylinders\"]\n","assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n","data = assembler.transform(data).select(\"Make\", \"Model\", \"features\", \"CO2 Emissions(g/km)\")\n","\n","# Train-Test Split\n","train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n","\n","# Regression Model\n","from pyspark.ml.regression import LinearRegression\n","\n","lr = LinearRegression(featuresCol=\"features\", labelCol=\"CO2 Emissions(g/km)\")\n","lr_model = lr.fit(train_data)\n","\n","# Predictions\n","predictions = lr_model.transform(test_data)\n","\n","# Evaluation\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","evaluator = RegressionEvaluator(labelCol=\"CO2 Emissions(g/km)\", predictionCol=\"prediction\")\n","rmse = evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n","r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n","\n","print(f\"RMSE: {rmse}\")\n","print(f\"R²: {r2}\")\n","\n","\n"]},{"cell_type":"code","source":["# --------------------- TASK 3: K-MEANS CLUSTERING --------------------- #\n","\n","original_data = spark.read.csv(\"/content/CO2 Emissions_Canada.csv\", header=True, inferSchema=True)\n","\n","from pyspark.ml.feature import StandardScaler\n","\n","clustering_features = [\"Fuel Consumption City (L/100 km)\",\n","                       \"Fuel Consumption Hwy (L/100 km)\",\n","                       \"Fuel Consumption Comb (L/100 km)\",\n","                       \"CO2 Emissions(g/km)\"]\n","\n","assembler = VectorAssembler(inputCols=clustering_features, outputCol=\"features\")\n","clustering_data = assembler.transform(original_data).select(\"Make\", \"Model\", \"features\")\n","\n","scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n","scaled_data = scaler.fit(clustering_data).transform(clustering_data)\n","\n","from pyspark.ml.clustering import KMeans\n","\n","kmeans = KMeans(featuresCol=\"scaled_features\", k=3, seed=42)\n","model = kmeans.fit(scaled_data)\n","clustered_data = model.transform(scaled_data)\n","\n","# Convert cluster index to labels\n","cluster_labels = {0: \"Low Emission\", 1: \"Medium Emission\", 2: \"High Emission\"}\n","label_udf = udf(lambda x: cluster_labels.get(int(x), \"Unknown\"), StringType())\n","\n","clustered_data = clustered_data.withColumn(\"Cluster Label\", label_udf(\"prediction\"))\n","\n","from pyspark.sql.types import ArrayType, FloatType\n","from pyspark.sql.functions import udf\n","\n","# Define UDF to convert vector column to an array\n","vector_to_array_udf = udf(lambda vector: vector.toArray().tolist(), ArrayType(FloatType()))\n","\n","# Convert 'features' to an array column\n","clustered_data = clustered_data.withColumn(\"features_array\", vector_to_array_udf(\"features\"))\n","\n","# Extract each feature into its own column\n","for i, col_name in enumerate(clustering_features):\n","    clustered_data = clustered_data.withColumn(col_name, clustered_data[\"features_array\"][i])\n","\n","# Drop the intermediate array column\n","clustered_data = clustered_data.drop(\"features_array\")\n","\n","\n","# Remove unnecessary columns\n","clustered_data = clustered_data.select(\"Make\", \"Model\", \"Fuel Consumption City (L/100 km)\",\n","                                       \"Fuel Consumption Hwy (L/100 km)\", \"Fuel Consumption Comb (L/100 km)\",\n","                                       \"CO2 Emissions(g/km)\", \"Cluster Label\")\n","\n","# Save as CSV\n","clustered_data.toPandas().to_csv(\"clustered_data.csv\", index=False)"],"metadata":{"id":"8IceptXh6QhF","executionInfo":{"status":"ok","timestamp":1738657820872,"user_tz":-345,"elapsed":16618,"user":{"displayName":"Subhash Dhakal","userId":"00152720141340506237"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# --------------------- TASK 4: CLASSIFICATION --------------------- #\n","from pyspark.sql.functions import when, col\n","\n","classification_data = original_data.withColumn(\n","    \"emission_category\",\n","    when(col(\"CO2 Emissions(g/km)\") <= 150, \"Low\")\n","    .when((col(\"CO2 Emissions(g/km)\") > 150) & (col(\"CO2 Emissions(g/km)\") <= 250), \"Medium\")\n","    .otherwise(\"High\")\n",")\n","\n","from pyspark.ml.feature import StringIndexer\n","\n","indexer = StringIndexer(inputCol=\"emission_category\", outputCol=\"label\")\n","classification_data = indexer.fit(classification_data).transform(classification_data)\n","\n","features = [\"Engine Size(L)\", \"Cylinders\", \"Fuel Consumption Comb (L/100 km)\"]\n","assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n","\n","classification_data = assembler.transform(classification_data).select(\"Make\", \"Model\", \"features\", \"label\")\n","\n","from pyspark.ml.classification import DecisionTreeClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","# Train-Test Split\n","train_data, test_data = classification_data.randomSplit([0.8, 0.2], seed=42)\n","\n","# Train the model\n","dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n","dt_model = dt.fit(train_data)\n","\n","# Predictions\n","predictions = dt_model.transform(test_data)\n","\n","# Evaluate Model\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(predictions)\n","\n","print(f\"Decision Tree Accuracy: {accuracy:.4f}\")\n","print(\"Feature Importances: \", dt_model.featureImportances)\n","\n","# Convert numerical predictions back to categorical labels\n","def label_to_category(label):\n","    mapping = {0.0: \"Low\", 1.0: \"Medium\", 2.0: \"High\"}\n","    return mapping.get(label, \"Unknown\")\n","\n","label_to_category_udf = udf(label_to_category, StringType())\n","\n","predictions = predictions.withColumn(\"Predicted Category\", label_to_category_udf(\"prediction\"))\n","predictions = predictions.withColumn(\"Actual Category\", label_to_category_udf(\"label\"))\n","\n","# Save only necessary columns\n","predictions = predictions.select(\"Make\", \"Model\", \"Actual Category\", \"Predicted Category\")\n","\n","# Save as CSV\n","predictions.toPandas().to_csv(\"classification_results.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ryX2hOL4_7a","executionInfo":{"status":"ok","timestamp":1738657826690,"user_tz":-345,"elapsed":5829,"user":{"displayName":"Subhash Dhakal","userId":"00152720141340506237"}},"outputId":"d61e227b-38f0-4bb9-eaaa-e1ae616a42cd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Decision Tree Accuracy: 0.9567\n","Feature Importances:  (3,[0,1,2],[0.01696196241810251,0.0004482826209203784,0.9825897549609771])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"aqXGI1QA9Pgm","executionInfo":{"status":"ok","timestamp":1738657826692,"user_tz":-345,"elapsed":7,"user":{"displayName":"Subhash Dhakal","userId":"00152720141340506237"}}},"execution_count":3,"outputs":[]}]}